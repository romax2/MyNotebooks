{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Column NLI Model - Final - Multi Domain Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romax2/MyNotebooks/blob/main/Column_NLI_Model_Final_Multi_Domain_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning Project Template\n",
        "By Mario Ramirez<br>\n",
        "*Revised on June 3, 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Beg7Qq08yFH8"
      },
      "source": [
        "Check env device, connect to gdrive, installing transformers and importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qdr85Yb4r72",
        "outputId": "033d9534-8ad7-4339-8218-a61d5b905f6b"
      },
      "source": [
        "#! mkdir './data/'\n",
        "#! mkdir './models/'\n",
        "#! ls -l\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "# source_folder = './data'\n",
        "# destination_folder = './models'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q"
      },
      "source": [
        "#!pip install transformers --quiet\n",
        "!pip install transformers --quiet"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HM6qXur6eYT"
      },
      "source": [
        "!pip install umap-learn --quiet"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrRBjtHx6kfX"
      },
      "source": [
        "#!pip install hdbscan --quiet"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUACsSla7RkB"
      },
      "source": [
        "#!pip install sentence-transformers --quiet"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpdoQ_YGyQCs"
      },
      "source": [
        "# Libraries\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "# Preliminaries\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "# Models\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "# Training\n",
        "import torch.optim as optim\n",
        "# Evaluation\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import umap"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgLQKnEHu7MB",
        "outputId": "27279f28-473f-4ee4-a39d-3e872cf65d0c"
      },
      "source": [
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(DEVICE)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxddqmruamSj"
      },
      "source": [
        "The code in this notebook is actually a simplified version of the [run_glue.py](https://github.com/huggingface/transformers/blob/master/examples/run_glue.py) example script from huggingface.\n",
        "\n",
        "`run_glue.py` is a helpful utility which allows you to pick which GLUE benchmark task you want to run on, and which pre-trained model you want to use (you can see the list of possible models [here](https://github.com/huggingface/transformers/blob/e6cff60b4cbc1158fbd6e4a1c3afda8dc224f566/examples/run_glue.py#L69)). It also supports using either the CPU, a single GPU, or multiple GPUs. It even supports using 16-bit precision if you want further speed up.\n",
        "\n",
        "Unfortunately, all of this configurability comes at the cost of *readability*. In this Notebook, we've simplified the code greatly and added plenty of comments to make it clear what's going on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "# 2. Loading and setting up Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IygEiMSwPmG0",
        "outputId": "ecfce565-6ecd-48e9-a7cb-48d2ea6df4a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnxPdSkGS1dp",
        "outputId": "fa50f4b5-bfd3-4e4a-93a1-68f1b25382ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_data\n",
            "columnBased-preprocessed-calderdalebusinessdata.csv\n",
            "columnBased-preprocessed.csv\n",
            "columnBased-preprocessed-domain.csv\n",
            "columnBased-preprocessed-foodhygiene.csv\n",
            "columnBased-preprocessed-foodhygieneSmall.csv\n",
            "columnBased-preprocessed-salaries.csv\n",
            "columnBased-preprocessed-salariesSmall.csv\n",
            "columnBased-preprocessed-small.csv\n",
            "columnBased-raw.csv\n",
            "frame\n",
            "NLI_GT_DATA.csv\n",
            "salaries.csv\n",
            "TableDataset20210527.csv\n",
            "tutorials\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AitOxy78X423",
        "outputId": "d523f36a-0ad9-4960-f305-e8986515d545"
      },
      "source": [
        "#source_folder = 'gdrive/MyDrive/data/'\n",
        "source_folder = '/content/gdrive/MyDrive/data/'\n",
        "destination_folder = 'gdrive/MyDrive/models/'\n",
        "raw_data = pd.read_csv(source_folder+\"clean_data/columnBased-preprocessed-pub.csv\")\n",
        "#raw_data.head()\n",
        "raw_data.shape"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13041, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJZJ5HpUVjp0",
        "outputId": "c0d6cf4b-b29d-4d11-9086-15e1a39c28d6"
      },
      "source": [
        "dfg = raw_data.groupby(['collectionName'])['collectionName'].count()\n",
        "print(dfg)\n",
        "#dfg.plot(kind='bar', title='Data domains/collections', ylabel='Count', xlabel='dataset split', figsize=(6, 5))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "collectionName\n",
            "calderdalebusinessdata     831\n",
            "foodhygiene               5422\n",
            "salaries                  6788\n",
            "Name: collectionName, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UybMJzP7kPho"
      },
      "source": [
        "#PerPublisher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_tNtREdZBM_"
      },
      "source": [
        "def clean_data(data, cols):\n",
        "  for col_name in cols:\n",
        "    data[col_name] = data[col_name].apply(lambda v: re.sub(r\"[\\-,.;@#?!&$\\)\\(]+\\ *\", \" \", v.lower()))\n",
        "\n",
        "def split_data_func(data, collection_name):\n",
        "  data['data_type'] = ['train']*data.shape[0]\n",
        "  data.loc[data['collectionName'] == collection_name, 'data_type'] = 'val'\n",
        "  \n",
        "def print_data_summary(data):\n",
        "  dfg = data.groupby(['data_type'])['data_type'].count()\n",
        "  print(dfg)\n",
        "\n",
        "\n",
        "def split_data_by_publisher(data, publisher):\n",
        "  data['data_type'] = ['train']*data.shape[0]\n",
        "  data.loc[data['candidatePublisher'] == publisher, 'data_type'] = 'val'"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvlLj9IbiC3q",
        "outputId": "5fb5e0a6-6156-40b3-d600-abea57c8ca94"
      },
      "source": [
        "perPublisher=True\n",
        "\n",
        "if perPublisher==True:\n",
        "  raw_data = raw_data[raw_data.collectionName == \"salaries\"]\n",
        "  dfg = raw_data.groupby(['collectionName'])['collectionName'].count()\n",
        "  print(dfg)\n",
        "  dfg = raw_data.groupby(['candidatePublisher'])['candidatePublisher'].count()\n",
        "  print(dfg)\n",
        "  #split_data_by_publisher(raw_data, 'Cabinet Office')\n",
        "  #split_data_by_publisher(raw_data, 'Ministry of Defence')\n",
        "  #split_data_by_publisher(raw_data, 'Department for Business, Innovation and Skills')\n",
        "  split_data_by_publisher(raw_data, 'UK Statistics Authority')\n",
        "else:\n",
        "  split_data_func(raw_data, 'salaries')\n",
        "  #split_data_func(raw_data, 'calderdalebusinessdata')\n",
        "  #split_data_func(raw_data, 'foodhygiene')"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "collectionName\n",
            "salaries    6788\n",
            "Name: collectionName, dtype: int64\n",
            "candidatePublisher\n",
            "Cabinet Office                                    2028\n",
            "Department for Business, Innovation and Skills     297\n",
            "Ministry of Defence                                803\n",
            "UK Statistics Authority                            292\n",
            "Name: candidatePublisher, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "73JQ8NLvZ3sQ",
        "outputId": "52c9811c-1772-481d-d1a4-3c3fa0e6a43b"
      },
      "source": [
        "print_data_summary(raw_data)\n",
        "raw_data.head()\n",
        "\n",
        "\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_type\n",
            "train    6496\n",
            "val       292\n",
            "Name: data_type, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>collectionName</th>\n",
              "      <th>gtKey</th>\n",
              "      <th>targetPublisher</th>\n",
              "      <th>target_ds</th>\n",
              "      <th>targetAttPrefix</th>\n",
              "      <th>targetKey</th>\n",
              "      <th>xt1</th>\n",
              "      <th>xt2</th>\n",
              "      <th>xt3</th>\n",
              "      <th>candidatePublisher</th>\n",
              "      <th>candidate_ds</th>\n",
              "      <th>candidateAttPrefix</th>\n",
              "      <th>candidateKey</th>\n",
              "      <th>yt1</th>\n",
              "      <th>yt2</th>\n",
              "      <th>yt3</th>\n",
              "      <th>value</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_cpdoycs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>cpdoycs</td>\n",
              "      <td>0JUSLET_cpdoycs</td>\n",
              "      <td>Payscale Minimum is property of 150930 Organog...</td>\n",
              "      <td>Payscale Minimum is property of 150930 Organog...</td>\n",
              "      <td>Payscale Minimum is property of 150930 Organog...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jfcykcm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jfcykcm</td>\n",
              "      <td>0JUSLET_jfcykcm</td>\n",
              "      <td>Parent Department is property of 150930 Organo...</td>\n",
              "      <td>Parent Department is property of 150930 Organo...</td>\n",
              "      <td>Parent Department is property of 150930 Organo...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jnmpagp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jnmpagp</td>\n",
              "      <td>0JUSLET_jnmpagp</td>\n",
              "      <td>Organisation is property of 150930 Organogram ...</td>\n",
              "      <td>Organisation is property of 150930 Organogram ...</td>\n",
              "      <td>Organisation is property of 150930 Organogram ...</td>\n",
              "      <td>ALT</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_liuxawt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>liuxawt</td>\n",
              "      <td>0JUSLET_liuxawt</td>\n",
              "      <td>Reporting Senior Post is property of 150930 Or...</td>\n",
              "      <td>Reporting Senior Post is property of 150930 Or...</td>\n",
              "      <td>Reporting Senior Post is property of 150930 Or...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_mccsbjf</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>mccsbjf</td>\n",
              "      <td>0JUSLET_mccsbjf</td>\n",
              "      <td>Grade is property of 150930 Organogram Data Ho...</td>\n",
              "      <td>Grade is property of 150930 Organogram Data Ho...</td>\n",
              "      <td>Grade is property of 150930 Organogram Data Ho...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  collectionName                             gtKey  ... value data_type\n",
              "0       salaries  0G81FDQ_clxhxmv--0JUSLET_cpdoycs  ...   IND     train\n",
              "1       salaries  0G81FDQ_clxhxmv--0JUSLET_jfcykcm  ...   IND     train\n",
              "2       salaries  0G81FDQ_clxhxmv--0JUSLET_jnmpagp  ...   ALT     train\n",
              "3       salaries  0G81FDQ_clxhxmv--0JUSLET_liuxawt  ...   IND     train\n",
              "4       salaries  0G81FDQ_clxhxmv--0JUSLET_mccsbjf  ...   IND     train\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "raKNGsJ7byr8",
        "outputId": "81173c7f-0a8b-450b-d4c0-b5fd40eeb1e3"
      },
      "source": [
        "clean_data(raw_data, ['xt1','xt2','xt3','yt1','yt2','yt3',])\n",
        "raw_data.head()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>collectionName</th>\n",
              "      <th>gtKey</th>\n",
              "      <th>targetPublisher</th>\n",
              "      <th>target_ds</th>\n",
              "      <th>targetAttPrefix</th>\n",
              "      <th>targetKey</th>\n",
              "      <th>xt1</th>\n",
              "      <th>xt2</th>\n",
              "      <th>xt3</th>\n",
              "      <th>candidatePublisher</th>\n",
              "      <th>candidate_ds</th>\n",
              "      <th>candidateAttPrefix</th>\n",
              "      <th>candidateKey</th>\n",
              "      <th>yt1</th>\n",
              "      <th>yt2</th>\n",
              "      <th>yt3</th>\n",
              "      <th>value</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_cpdoycs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>cpdoycs</td>\n",
              "      <td>0JUSLET_cpdoycs</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jfcykcm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jfcykcm</td>\n",
              "      <td>0JUSLET_jfcykcm</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jnmpagp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jnmpagp</td>\n",
              "      <td>0JUSLET_jnmpagp</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>ALT</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_liuxawt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>liuxawt</td>\n",
              "      <td>0JUSLET_liuxawt</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_mccsbjf</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>mccsbjf</td>\n",
              "      <td>0JUSLET_mccsbjf</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  collectionName                             gtKey  ... value data_type\n",
              "0       salaries  0G81FDQ_clxhxmv--0JUSLET_cpdoycs  ...   IND     train\n",
              "1       salaries  0G81FDQ_clxhxmv--0JUSLET_jfcykcm  ...   IND     train\n",
              "2       salaries  0G81FDQ_clxhxmv--0JUSLET_jnmpagp  ...   ALT     train\n",
              "3       salaries  0G81FDQ_clxhxmv--0JUSLET_liuxawt  ...   IND     train\n",
              "4       salaries  0G81FDQ_clxhxmv--0JUSLET_mccsbjf  ...   IND     train\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "OiU6aQOX4IaW",
        "outputId": "13cebb0b-c529-4131-bf31-80685cde70a8"
      },
      "source": [
        "dfg = raw_data.groupby(['value'])['value'].count()\n",
        "dfg.plot(kind='bar', title='Data distribution', ylabel='Count', xlabel='Entailment Relation', figsize=(6, 5))\n",
        "raw_data.head()"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>collectionName</th>\n",
              "      <th>gtKey</th>\n",
              "      <th>targetPublisher</th>\n",
              "      <th>target_ds</th>\n",
              "      <th>targetAttPrefix</th>\n",
              "      <th>targetKey</th>\n",
              "      <th>xt1</th>\n",
              "      <th>xt2</th>\n",
              "      <th>xt3</th>\n",
              "      <th>candidatePublisher</th>\n",
              "      <th>candidate_ds</th>\n",
              "      <th>candidateAttPrefix</th>\n",
              "      <th>candidateKey</th>\n",
              "      <th>yt1</th>\n",
              "      <th>yt2</th>\n",
              "      <th>yt3</th>\n",
              "      <th>value</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_cpdoycs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>cpdoycs</td>\n",
              "      <td>0JUSLET_cpdoycs</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jfcykcm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jfcykcm</td>\n",
              "      <td>0JUSLET_jfcykcm</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jnmpagp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jnmpagp</td>\n",
              "      <td>0JUSLET_jnmpagp</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>ALT</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_liuxawt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>liuxawt</td>\n",
              "      <td>0JUSLET_liuxawt</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_mccsbjf</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>mccsbjf</td>\n",
              "      <td>0JUSLET_mccsbjf</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  collectionName                             gtKey  ... value data_type\n",
              "0       salaries  0G81FDQ_clxhxmv--0JUSLET_cpdoycs  ...   IND     train\n",
              "1       salaries  0G81FDQ_clxhxmv--0JUSLET_jfcykcm  ...   IND     train\n",
              "2       salaries  0G81FDQ_clxhxmv--0JUSLET_jnmpagp  ...   ALT     train\n",
              "3       salaries  0G81FDQ_clxhxmv--0JUSLET_liuxawt  ...   IND     train\n",
              "4       salaries  0G81FDQ_clxhxmv--0JUSLET_mccsbjf  ...   IND     train\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "## 2.2. Parse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeyVCXT31EZQ"
      },
      "source": [
        "Clean up descriptors in dataset, remove unwanted columns from dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2IwVKFw7kFS"
      },
      "source": [
        "Spliting into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "2u3idPIJ6t7l",
        "outputId": "c44d51d4-1275-488b-d8b4-6835918af7a1"
      },
      "source": [
        "#DATA SPLIT\n",
        "label_dict = {label: i for i, label in enumerate(raw_data.value.unique())}\n",
        "print(label_dict)\n",
        "\n",
        "#BEFORE\n",
        "#raw_data['data_type'] = ['not_set']*raw_data.shape[0]\n",
        "#raw_data.loc[X_train, 'data_type'] = 'train'\n",
        "#raw_data.loc[X_val, 'data_type'] = 'val'\n",
        "\n",
        "#AFTER\n",
        "#raw_data['data_type'] = ['not_set']*raw_data.shape[0]\n",
        "\n",
        "raw_data['label'] = raw_data.value.replace(label_dict)\n",
        "raw_data.groupby(['value', 'data_type']).count()"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'IND': 0, 'ALT': 1, 'EQ': 2}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>collectionName</th>\n",
              "      <th>gtKey</th>\n",
              "      <th>targetPublisher</th>\n",
              "      <th>target_ds</th>\n",
              "      <th>targetAttPrefix</th>\n",
              "      <th>targetKey</th>\n",
              "      <th>xt1</th>\n",
              "      <th>xt2</th>\n",
              "      <th>xt3</th>\n",
              "      <th>candidatePublisher</th>\n",
              "      <th>candidate_ds</th>\n",
              "      <th>candidateAttPrefix</th>\n",
              "      <th>candidateKey</th>\n",
              "      <th>yt1</th>\n",
              "      <th>yt2</th>\n",
              "      <th>yt3</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">ALT</th>\n",
              "      <th>train</th>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>0</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>1898</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "      <td>3848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>0</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "      <td>292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EQ</th>\n",
              "      <th>train</th>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>1225</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>1225</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "      <td>2606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IND</th>\n",
              "      <th>train</th>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 collectionName  gtKey  targetPublisher  ...   yt2   yt3  label\n",
              "value data_type                                          ...                   \n",
              "ALT   train                3848   3848                0  ...  3848  3848   3848\n",
              "      val                   292    292                0  ...   292   292    292\n",
              "EQ    train                2606   2606             1225  ...  2606  2606   2606\n",
              "IND   train                  42     42                0  ...    42    42     42\n",
              "\n",
              "[4 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Let's extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldgNb_WS87dD",
        "outputId": "c85bfe5c-b280-4c62-b9c8-58972f1018d3"
      },
      "source": [
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSeuas069aEa",
        "outputId": "117c3818-3000-4200-8a8f-398909e894b8"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "txsentences = raw_data.xt3.values\n",
        "tysentences = raw_data.yt3.values\n",
        "#labels = df.label.values\n",
        "print(' Original: ', txsentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(txsentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(txsentences[0])))\n",
        "\n",
        "\n"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  organisation is property of her majestys revenue and customs 30 09 2011 hmrc 300911 hmrc organogram final junior and is related to parent department and unit and has values her majesty's revenue and customs\n",
            "Tokenized:  ['organisation', 'is', 'property', 'of', 'her', 'majesty', '##s', 'revenue', 'and', 'customs', '30', '09', '2011', 'hm', '##rc', '300', '##9', '##11', 'hm', '##rc', 'organ', '##og', '##ram', 'final', 'junior', 'and', 'is', 'related', 'to', 'parent', 'department', 'and', 'unit', 'and', 'has', 'values', 'her', 'majesty', \"'\", 's', 'revenue', 'and', 'customs']\n",
            "Token IDs:  [5502, 2003, 3200, 1997, 2014, 9995, 2015, 6599, 1998, 8205, 2382, 5641, 2249, 20287, 11890, 3998, 2683, 14526, 20287, 11890, 5812, 8649, 6444, 2345, 3502, 1998, 2003, 3141, 2000, 6687, 2533, 1998, 3131, 1998, 2038, 5300, 2014, 9995, 1005, 1055, 6599, 1998, 8205]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOk_a-Cx-mlp",
        "outputId": "cfe00699-7745-45d2-a8fe-e9e726d58086"
      },
      "source": [
        "max_l = 0\n",
        "\n",
        "for sent in txsentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True) # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    max_l = max(max_l, len(input_ids))    # Update the maximum sentence length.\n",
        "\n",
        "for sent in tysentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_l = max(max_l, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_l)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld4pu9dg99A3"
      },
      "source": [
        "Tokenizing all dataset will:\n",
        "  (1) Tokenize the sentence.<br>\n",
        "  (2) Prepend the `[CLS]` token to the start.<br>\n",
        "  (3) Append the `[SEP]` token to the end.<br>\n",
        "  (4) Map tokens to their IDs.<br>\n",
        "  (5) Pad or truncate the sentence to `max_length`<br>\n",
        "  (6) Create attention masks for [PAD] tokens.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z3ft3IM-AzN"
      },
      "source": [
        "max_len = 256\n",
        "#max_len = 128\n",
        "encoded_data_train = tokenizer.batch_encode_plus(zip(raw_data[raw_data.data_type=='train'].xt3.values.tolist(), raw_data[raw_data.data_type=='train'].yt3.values.tolist()), \n",
        "                                                 is_split_into_words=False, \n",
        "                                                 padding=True,\n",
        "                                                 add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "                                                 return_attention_mask=True,# Construct attn. masks.\n",
        "                                                 max_length=max_len,# Pad & truncate all sentences.\n",
        "                                                 return_tensors='pt')# Return pytorch tensors.\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(raw_data[raw_data.data_type=='train'].label.values)\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(zip(raw_data[raw_data.data_type=='val'].xt3.values.tolist(), raw_data[raw_data.data_type=='val'].yt3.values.tolist()),\n",
        "                                               is_split_into_words=False, \n",
        "                                               padding=True,\n",
        "                                               add_special_tokens=True,\n",
        "                                               return_attention_mask=True,\n",
        "                                               max_length=max_len,\n",
        "                                               return_tensors='pt')\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(raw_data[raw_data.data_type=='val'].label.values)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEUSEhoqDmUo"
      },
      "source": [
        "Visual Characterization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOp4opzNCYe4",
        "outputId": "cf026639-163a-49da-d2cc-fa3b0e428961"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
        "len(dataset_train), len(dataset_val)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6496, 292)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_p9KetCC3G1"
      },
      "source": [
        "Create dataset iterator by using torch DataLoader class. This avoids loading the dataset into memory, which is memory efficient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLYAzLf8C6Af"
      },
      "source": [
        "BATCH_SIZE = 3 #DataLoader needs to know this (BERT recomendation is 16 or 32)\n",
        "#BATCH_SIZE = 16 #DataLoader needs to know this (BERT recomendation is 16 or 32)\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, #training samples\n",
        "                              sampler=RandomSampler(dataset_train), #select batches randomly\n",
        "                              batch_size=BATCH_SIZE)#train with this batch size\n",
        "dataloader_validation = DataLoader(dataset_val, #validation samples\n",
        "                                   sampler=SequentialSampler(dataset_val), #take batches sequentially\n",
        "                                   batch_size=BATCH_SIZE)# evaluate using this batch size"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "# 4. Set up Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX"
      },
      "source": [
        "Configuring model..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_YUH6r7ENjW",
        "outputId": "b5c64d14-5227-4915-9e91-b3213b57be87"
      },
      "source": [
        "EPOCHS = 5\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",  #Use 12-layer BERT model, with uncased vocab.\n",
        "                                                      num_labels=len(label_dict), #number of output labels\n",
        "                                                      output_attentions=False, #Whether model returns attentions weights\n",
        "                                                      output_hidden_states=False)#Whether the model returns all hidden-states\n",
        "\n",
        "#Weight Decay fix\n",
        "optimizer = AdamW(model.parameters(), \n",
        "                  lr=1e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps=1e-8)# args.adam_epsilon  - default is 1e-8.\n",
        "\n",
        "#learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*EPOCHS)\n",
        "\n",
        "model.cuda()                                                      "
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc4Qxfw1Frbc",
        "outputId": "8b4a2066-424d-46a1-ea59-d800b6b88e05"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## 4.1. Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUAH8qQSMnn1"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "  label_dict_inverse = {v: k for k, v in label_dict.items()}  \n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "\n",
        "  for label in np.unique(labels_flat):\n",
        "    y_preds = preds_flat[labels_flat==label]\n",
        "    y_true = labels_flat[labels_flat==label]\n",
        "    print(f'Class: {label_dict_inverse[label]}')\n",
        "    print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}' + ', ' + str(len(y_preds[y_preds==label])/len(y_true)) + '\\n')\n",
        "\n",
        "def evaluate(model, dataloader_val, device):\n",
        "  model.eval()\n",
        "  loss_val_total = 0\n",
        "  predictions, true_vals = [], []\n",
        "    \n",
        "  for batch in dataloader_val:   \n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "    inputs = {'input_ids':      batch[0],\n",
        "              'attention_mask': batch[1],\n",
        "              'labels':         batch[2],\n",
        "              }\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**inputs)\n",
        "      \n",
        "      loss = outputs[0]\n",
        "      logits = outputs[1]\n",
        "      loss_val_total += loss.item()\n",
        "\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = inputs['labels'].cpu().numpy()\n",
        "      predictions.append(logits)\n",
        "      true_vals.append(label_ids)\n",
        "    \n",
        "  loss_val_avg = loss_val_total/len(dataloader_val)   \n",
        "  predictions = np.concatenate(predictions, axis=0)\n",
        "  true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "  return loss_val_avg, predictions, true_vals\n",
        "\n",
        "def single_eval():\n",
        "  print(\"single eval\")\n",
        "\n",
        "def train(model, epochs,dataloader_train, dataloader_validation, optimizer, scheduler, device='cpu'):\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  for epoch in tqdm(range(1, epochs+1)):\n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "      model.zero_grad()\n",
        "      batch = tuple(b.to(device) for b in batch)\n",
        "      inputs = {'input_ids': batch[0],\n",
        "                'attention_mask': batch[1],\n",
        "                'labels': batch[2],\n",
        "                }       \n",
        "      outputs = model(**inputs)\n",
        "        \n",
        "      loss = outputs[0]\n",
        "      loss_train_total += loss.item()\n",
        "      loss.backward()\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "        \n",
        "      progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "    #torch.save(model.state_dict(), f'./models/finetuned_BERT_epoch_{epoch}.model')   \n",
        "    torch.save(model.state_dict(), f'gdrive/MyDrive/models/finetuned_BERT_epoch_{epoch}.model')   \n",
        "\n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(model, dataloader_validation, device=device)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz5Qlp6hsMDj"
      },
      "source": [
        "## 4.2. Verbose Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1hffmqsQzk"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def train_verbose_model(model, epochs,dataloader_train, dataloader_validation, optimizer, scheduler, device='cpu'):\n",
        "  # We'll store a number of quantities such as training and validation loss, \n",
        "  # validation accuracy, and timings.\n",
        "  training_stats = []\n",
        "\n",
        "  # Measure the total training time for the whole run.\n",
        "  total_t0 = time.time()\n",
        "\n",
        "  # For each epoch...\n",
        "  for epoch_i in range(0, epochs):\n",
        "      # ========================================\n",
        "      #               Training\n",
        "      # ========================================\n",
        "      \n",
        "      # Perform one full pass over the training set.\n",
        "      print(\"\")\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "      print('Training...')\n",
        "\n",
        "      # Measure how long the training epoch takes.\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Reset the total loss for this epoch.\n",
        "      total_train_loss = 0\n",
        "\n",
        "      # Put the model into training mode. Don't be mislead--the call to \n",
        "      # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "      # `dropout` and `batchnorm` layers behave differently during training\n",
        "      # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "      model.train()\n",
        "\n",
        "      # For each batch of training data...\n",
        "      for step, batch in enumerate(dataloader_train):\n",
        "\n",
        "          # Progress update every 40 batches.\n",
        "          #if step % 40 == 0 and not step == 0:\n",
        "          if step % 200 == 0 and not step == 0:\n",
        "              # Calculate elapsed time in minutes.\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "              # Report progress.\n",
        "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(dataloader_train), elapsed))\n",
        "\n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "          # `to` method.\n",
        "          #\n",
        "          # `batch` contains three pytorch tensors:\n",
        "          #   [0]: input ids \n",
        "          #   [1]: attention masks\n",
        "          #   [2]: labels \n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "\n",
        "          # Always clear any previously calculated gradients before performing a\n",
        "          # backward pass. PyTorch doesn't do this automatically because \n",
        "          # accumulating the gradients is \"convenient while training RNNs\". \n",
        "          # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "          model.zero_grad()        \n",
        "\n",
        "          # Perform a forward pass (evaluate the model on this training batch).\n",
        "          # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "          # function and pass down the arguments. The `forward` function is \n",
        "          # documented here: \n",
        "          # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "          # The results are returned in a results object, documented here:\n",
        "          # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "          # Specifically, we'll get the loss (because we provided labels) and the\n",
        "          # \"logits\"--the model outputs prior to activation.\n",
        "          result = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels,\n",
        "                        return_dict=True)\n",
        "\n",
        "          loss = result.loss\n",
        "          logits = result.logits\n",
        "\n",
        "          # Accumulate the training loss over all of the batches so that we can\n",
        "          # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "          # single value; the `.item()` function just returns the Python value \n",
        "          # from the tensor.\n",
        "          total_train_loss += loss.item()\n",
        "\n",
        "          # Perform a backward pass to calculate the gradients.\n",
        "          loss.backward()\n",
        "\n",
        "          # Clip the norm of the gradients to 1.0.\n",
        "          # This is to help prevent the \"exploding gradients\" problem.\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "          # Update parameters and take a step using the computed gradient.\n",
        "          # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "          # modified based on their gradients, the learning rate, etc.\n",
        "          optimizer.step()\n",
        "\n",
        "          # Update the learning rate.\n",
        "          scheduler.step()\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_train_loss = total_train_loss / len(dataloader_train)            \n",
        "      \n",
        "      # Measure how long this epoch took.\n",
        "      training_time = format_time(time.time() - t0)\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "      print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "          \n",
        "      # ========================================\n",
        "      #               Validation\n",
        "      # ========================================\n",
        "      # After the completion of each training epoch, measure our performance on\n",
        "      # our validation set.\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Running Validation...\")\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Put the model in evaluation mode--the dropout layers behave differently\n",
        "      # during evaluation.\n",
        "      model.eval()\n",
        "\n",
        "      # Tracking variables \n",
        "      total_eval_accuracy = 0\n",
        "      total_eval_loss = 0\n",
        "      nb_eval_steps = 0\n",
        "\n",
        "      # Evaluate data for one epoch\n",
        "      for batch in dataloader_validation:\n",
        "          \n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "          # the `to` method.\n",
        "          #\n",
        "          # `batch` contains three pytorch tensors:\n",
        "          #   [0]: input ids \n",
        "          #   [1]: attention masks\n",
        "          #   [2]: labels \n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "          \n",
        "          # Tell pytorch not to bother with constructing the compute graph during\n",
        "          # the forward pass, since this is only needed for backprop (training).\n",
        "          with torch.no_grad():        \n",
        "\n",
        "              # Forward pass, calculate logit predictions.\n",
        "              # token_type_ids is the same as the \"segment ids\", which \n",
        "              # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "              result = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_labels,\n",
        "                            return_dict=True)\n",
        "\n",
        "          # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "          # output values prior to applying an activation function like the \n",
        "          # softmax.\n",
        "          loss = result.loss\n",
        "          logits = result.logits\n",
        "              \n",
        "          # Accumulate the validation loss.\n",
        "          total_eval_loss += loss.item()\n",
        "\n",
        "          # Move logits and labels to CPU\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "          # Calculate the accuracy for this batch of test sentences, and\n",
        "          # accumulate it over all batches.\n",
        "          total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "          \n",
        "\n",
        "      # Report the final accuracy for this validation run.\n",
        "      avg_val_accuracy = total_eval_accuracy / len(dataloader_validation)\n",
        "      print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_val_loss = total_eval_loss / len(dataloader_validation)\n",
        "      \n",
        "      # Measure how long the validation run took.\n",
        "      validation_time = format_time(time.time() - t0)\n",
        "      \n",
        "      print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "      print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "      # Record all statistics from this epoch.\n",
        "      training_stats.append(\n",
        "          {\n",
        "              'epoch': epoch_i + 1,\n",
        "              'Training Loss': avg_train_loss,\n",
        "              'Valid. Loss': avg_val_loss,\n",
        "              'Valid. Accur.': avg_val_accuracy,\n",
        "              'Training Time': training_time,\n",
        "              'Validation Time': validation_time\n",
        "          }\n",
        "      )\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "\n",
        "  print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "  return training_stats"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.3. Execute Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhUEl5RPMheo",
        "outputId": "3cca4215-737d-4f0f-adf3-d542ecda960a"
      },
      "source": [
        "seed_val = 17#42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)    \n",
        "\n",
        "#train(model, EPOCHS, dataloader_train, dataloader_validation, optimizer, scheduler, device=DEVICE)\n",
        "my_stats = train_verbose_model(model, EPOCHS, dataloader_train, dataloader_validation, optimizer, scheduler, device=DEVICE)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch   200  of  2,166.    Elapsed: 0:01:02.\n",
            "  Batch   400  of  2,166.    Elapsed: 0:02:02.\n",
            "  Batch   600  of  2,166.    Elapsed: 0:03:02.\n",
            "  Batch   800  of  2,166.    Elapsed: 0:04:02.\n",
            "  Batch 1,000  of  2,166.    Elapsed: 0:05:02.\n",
            "  Batch 1,200  of  2,166.    Elapsed: 0:06:02.\n",
            "  Batch 1,400  of  2,166.    Elapsed: 0:07:02.\n",
            "  Batch 1,600  of  2,166.    Elapsed: 0:08:02.\n",
            "  Batch 1,800  of  2,166.    Elapsed: 0:09:03.\n",
            "  Batch 2,000  of  2,166.    Elapsed: 0:10:03.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:10:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:08\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch   200  of  2,166.    Elapsed: 0:01:00.\n",
            "  Batch   400  of  2,166.    Elapsed: 0:02:00.\n",
            "  Batch   600  of  2,166.    Elapsed: 0:03:00.\n",
            "  Batch   800  of  2,166.    Elapsed: 0:04:00.\n",
            "  Batch 1,000  of  2,166.    Elapsed: 0:05:01.\n",
            "  Batch 1,200  of  2,166.    Elapsed: 0:06:01.\n",
            "  Batch 1,400  of  2,166.    Elapsed: 0:07:01.\n",
            "  Batch 1,600  of  2,166.    Elapsed: 0:08:01.\n",
            "  Batch 1,800  of  2,166.    Elapsed: 0:09:01.\n",
            "  Batch 2,000  of  2,166.    Elapsed: 0:10:01.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:10:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:08\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch   200  of  2,166.    Elapsed: 0:01:00.\n",
            "  Batch   400  of  2,166.    Elapsed: 0:02:00.\n",
            "  Batch   600  of  2,166.    Elapsed: 0:03:00.\n",
            "  Batch   800  of  2,166.    Elapsed: 0:04:01.\n",
            "  Batch 1,000  of  2,166.    Elapsed: 0:05:01.\n",
            "  Batch 1,200  of  2,166.    Elapsed: 0:06:01.\n",
            "  Batch 1,400  of  2,166.    Elapsed: 0:07:02.\n",
            "  Batch 1,600  of  2,166.    Elapsed: 0:08:02.\n",
            "  Batch 1,800  of  2,166.    Elapsed: 0:09:02.\n",
            "  Batch 2,000  of  2,166.    Elapsed: 0:10:02.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:10:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:08\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch   200  of  2,166.    Elapsed: 0:01:00.\n",
            "  Batch   400  of  2,166.    Elapsed: 0:02:00.\n",
            "  Batch   600  of  2,166.    Elapsed: 0:03:01.\n",
            "  Batch   800  of  2,166.    Elapsed: 0:04:01.\n",
            "  Batch 1,000  of  2,166.    Elapsed: 0:05:01.\n",
            "  Batch 1,200  of  2,166.    Elapsed: 0:06:01.\n",
            "  Batch 1,400  of  2,166.    Elapsed: 0:07:02.\n",
            "  Batch 1,600  of  2,166.    Elapsed: 0:08:02.\n",
            "  Batch 1,800  of  2,166.    Elapsed: 0:09:02.\n",
            "  Batch 2,000  of  2,166.    Elapsed: 0:10:03.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:10:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:08\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch   200  of  2,166.    Elapsed: 0:01:00.\n",
            "  Batch   400  of  2,166.    Elapsed: 0:02:00.\n",
            "  Batch   600  of  2,166.    Elapsed: 0:03:01.\n",
            "  Batch   800  of  2,166.    Elapsed: 0:04:01.\n",
            "  Batch 1,000  of  2,166.    Elapsed: 0:05:01.\n",
            "  Batch 1,200  of  2,166.    Elapsed: 0:06:01.\n",
            "  Batch 1,400  of  2,166.    Elapsed: 0:07:01.\n",
            "  Batch 1,600  of  2,166.    Elapsed: 0:08:01.\n",
            "  Batch 1,800  of  2,166.    Elapsed: 0:09:02.\n",
            "  Batch 2,000  of  2,166.    Elapsed: 0:10:02.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:10:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:08\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:54:59 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "## 5. Summary of results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "cba2f66a-9b4b-4a4e-fb5a-27474ca7d463"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=my_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.44e-02</td>\n",
              "      <td>1.98e-04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0:10:53</td>\n",
              "      <td>0:00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.03e-02</td>\n",
              "      <td>3.78e-05</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0:10:51</td>\n",
              "      <td>0:00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.44e-05</td>\n",
              "      <td>1.47e-05</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0:10:52</td>\n",
              "      <td>0:00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.14e-03</td>\n",
              "      <td>7.49e-06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0:10:52</td>\n",
              "      <td>0:00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.06e-05</td>\n",
              "      <td>5.54e-06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0:10:52</td>\n",
              "      <td>0:00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1           6.44e-02     1.98e-04            1.0       0:10:53         0:00:08\n",
              "2           1.03e-02     3.78e-05            1.0       0:10:51         0:00:08\n",
              "3           6.44e-05     1.47e-05            1.0       0:10:52         0:00:08\n",
              "4           1.14e-03     7.49e-06            1.0       0:10:52         0:00:08\n",
              "5           1.06e-05     5.54e-06            1.0       0:10:52         0:00:08"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "(For reference, we are using 7,695 training samples and 856 validation samples).\n",
        "\n",
        "Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on. \n",
        "\n",
        "If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "b76c4ef0-160d-40c6-acd8-730c2a39f1be"
      },
      "source": [
        "% matplotlib inline\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KIUhsga1P_s"
      },
      "source": [
        "##5.1 Summary of metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efi7UXyX1Yci",
        "outputId": "f143e144-5ab4-4f47-d1aa-82dc2733fb9d"
      },
      "source": [
        "model = model.to(DEVICE)\n",
        "# _, predictions, true_vals = evaluate(model, dataloader_test, device=DEVICE)\n",
        "_, predictions, true_vals = evaluate(model, dataloader_validation, device=DEVICE)\n",
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: ALT\n",
            "Accuracy: 292/292, 1.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkS3ENpI1n1m",
        "outputId": "bcd931c0-8730-4854-939e-16576395506d"
      },
      "source": [
        "y_pred = np.argmax(predictions, axis=1)\n",
        "#print(classification_report(true_vals, y_pred, target_names=list(label_dict.keys())))\n",
        "print(classification_report(true_vals, y_pred, target_names=[\"ALT\"]))\n",
        "#print(classification_report(true_vals, y_pred, target_names=[\"IND\",\"EQ\",\"ALT\"]))"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ALT       1.00      1.00      1.00       292\n",
            "\n",
            "    accuracy                           1.00       292\n",
            "   macro avg       1.00      1.00      1.00       292\n",
            "weighted avg       1.00      1.00      1.00       292\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FdZ67aW1yMn",
        "outputId": "e8e891a0-238a-4dd7-a051-50a04a16e7da"
      },
      "source": [
        "len(dataset_train), len(dataset_val)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6496, 292)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd-Dbbnig5V5",
        "outputId": "999e91d0-a897-4af1-a65a-37d1ecdf5c81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDfCBEzeMSNI",
        "outputId": "eec92ad1-d295-4f63-c3ae-d68f2d8806cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd clean_data/results"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/data/clean_data/results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKIprV9aMXHH",
        "outputId": "75fd5ab4-8951-4381-95d7-277896e40c96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "out_data = raw_data[raw_data.data_type=='val']\n",
        "\n",
        "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
        "labels_flat = true_vals.flatten()\n",
        "out_data['mylabels'] = labels_flat.tolist()\n",
        "out_data['myPredictions'] = preds_flat.tolist()\n",
        "\n",
        "out_data.to_csv('output_publisher_UK_Statistics_Authority.csv')"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rPOKHoWP2jc",
        "outputId": "d2914086-aa2b-46b9-d24a-dee831333060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd ..\n",
        "%cd ..\n",
        "!pwd"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/data/clean_data\n",
            "/content/gdrive/My Drive/data\n",
            "/content/gdrive/My Drive/data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}