{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Column NLI Model - Final - Multi Domain Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romax2/MyNotebooks/blob/main/Column_NLI_Model_Final_Multi_Domain_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning Project Template\n",
        "By Mario Ramirez<br>\n",
        "*Revised on June 3, 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Beg7Qq08yFH8"
      },
      "source": [
        "Check env device, connect to gdrive, installing transformers and importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qdr85Yb4r72",
        "outputId": "e017c9a8-3c79-4278-f4c5-c732694b1144"
      },
      "source": [
        "#! mkdir './data/'\n",
        "#! mkdir './models/'\n",
        "#! ls -l\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "# source_folder = './data'\n",
        "# destination_folder = './models'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d5443c-f4c0-4a28-83d3-37b70ca379af"
      },
      "source": [
        "#!pip install transformers --quiet\n",
        "!pip install transformers --quiet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.5MB 30.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 33.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 38.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HM6qXur6eYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbfde4a-77c5-4f31-b2a2-65308a6932af"
      },
      "source": [
        "!pip install umap-learn --quiet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 16.4MB/s \n",
            "\u001b[?25h  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrRBjtHx6kfX"
      },
      "source": [
        "#!pip install hdbscan --quiet"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUACsSla7RkB"
      },
      "source": [
        "#!pip install sentence-transformers --quiet"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpdoQ_YGyQCs"
      },
      "source": [
        "# Libraries\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "# Preliminaries\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "# Models\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "# Training\n",
        "import torch.optim as optim\n",
        "# Evaluation\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import umap"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgLQKnEHu7MB",
        "outputId": "bff462b3-ac6f-4f55-f62a-adfc48520e53"
      },
      "source": [
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(DEVICE)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxddqmruamSj"
      },
      "source": [
        "The code in this notebook is actually a simplified version of the [run_glue.py](https://github.com/huggingface/transformers/blob/master/examples/run_glue.py) example script from huggingface.\n",
        "\n",
        "`run_glue.py` is a helpful utility which allows you to pick which GLUE benchmark task you want to run on, and which pre-trained model you want to use (you can see the list of possible models [here](https://github.com/huggingface/transformers/blob/e6cff60b4cbc1158fbd6e4a1c3afda8dc224f566/examples/run_glue.py#L69)). It also supports using either the CPU, a single GPU, or multiple GPUs. It even supports using 16-bit precision if you want further speed up.\n",
        "\n",
        "Unfortunately, all of this configurability comes at the cost of *readability*. In this Notebook, we've simplified the code greatly and added plenty of comments to make it clear what's going on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "# 2. Loading and setting up Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AitOxy78X423",
        "outputId": "97c56ac3-3607-4b14-b927-c986a2c6070a"
      },
      "source": [
        "source_folder = 'gdrive/MyDrive/data/'\n",
        "destination_folder = 'gdrive/MyDrive/models/'\n",
        "raw_data = pd.read_csv(source_folder+\"clean_data/columnBased-preprocessed-pub.csv\")\n",
        "#raw_data.head()\n",
        "raw_data.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13041, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN7XJyjchyN-"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJZJ5HpUVjp0",
        "outputId": "17108df5-cdb1-4b11-cbd6-f44001141f0a"
      },
      "source": [
        "dfg = raw_data.groupby(['collectionName'])['collectionName'].count()\n",
        "print(dfg)\n",
        "#dfg.plot(kind='bar', title='Data domains/collections', ylabel='Count', xlabel='dataset split', figsize=(6, 5))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "collectionName\n",
            "calderdalebusinessdata     831\n",
            "foodhygiene               5422\n",
            "salaries                  6788\n",
            "Name: collectionName, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UybMJzP7kPho"
      },
      "source": [
        "#PerPublisher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_tNtREdZBM_"
      },
      "source": [
        "def clean_data(data, cols):\n",
        "  for col_name in cols:\n",
        "    data[col_name] = data[col_name].apply(lambda v: re.sub(r\"[\\-,.;@#?!&$\\)\\(]+\\ *\", \" \", v.lower()))\n",
        "\n",
        "def split_data_func(data, collection_name):\n",
        "  data['data_type'] = ['train']*data.shape[0]\n",
        "  data.loc[data['collectionName'] == collection_name, 'data_type'] = 'val'\n",
        "  \n",
        "def print_data_summary(data):\n",
        "  dfg = data.groupby(['data_type'])['data_type'].count()\n",
        "  print(dfg)\n",
        "\n",
        "\n",
        "def split_data_by_publisher(data, publisher):\n",
        "  data['data_type'] = ['train']*data.shape[0]\n",
        "  data.loc[data['candidatePublisher'] == publisher, 'data_type'] = 'val'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvlLj9IbiC3q",
        "outputId": "4ec17518-0ff2-4ccc-873b-75be85fcc360"
      },
      "source": [
        "perPublisher=True\n",
        "\n",
        "if perPublisher==True:\n",
        "  raw_data = raw_data[raw_data.collectionName == \"salaries\"]\n",
        "  dfg = raw_data.groupby(['collectionName'])['collectionName'].count()\n",
        "  print(dfg)\n",
        "  dfg = raw_data.groupby(['candidatePublisher'])['candidatePublisher'].count()\n",
        "  print(dfg)\n",
        "  split_data_by_publisher(raw_data, 'Cabinet Office')\n",
        "  #split_data_by_publisher(raw_data, 'Ministry of Defence')\n",
        "  #split_data_by_publisher(raw_data, 'Department for Business, Innovation and Skills')\n",
        "  #split_data_by_publisher(raw_data, 'UK Statistics Authority')\n",
        "else:\n",
        "  split_data_func(raw_data, 'salaries')\n",
        "  #split_data_func(raw_data, 'calderdalebusinessdata')\n",
        "  #split_data_func(raw_data, 'foodhygiene')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "collectionName\n",
            "salaries    6788\n",
            "Name: collectionName, dtype: int64\n",
            "candidatePublisher\n",
            "Cabinet Office                                    2028\n",
            "Department for Business, Innovation and Skills     297\n",
            "Ministry of Defence                                803\n",
            "UK Statistics Authority                            292\n",
            "Name: candidatePublisher, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "73JQ8NLvZ3sQ",
        "outputId": "dff10ed6-11a1-4741-8ce8-bfe4924f387e"
      },
      "source": [
        "print_data_summary(raw_data)\n",
        "raw_data.head()\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_type\n",
            "train    4760\n",
            "val      2028\n",
            "Name: data_type, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>collectionName</th>\n",
              "      <th>gtKey</th>\n",
              "      <th>targetPublisher</th>\n",
              "      <th>target_ds</th>\n",
              "      <th>targetAttPrefix</th>\n",
              "      <th>targetKey</th>\n",
              "      <th>xt1</th>\n",
              "      <th>xt2</th>\n",
              "      <th>xt3</th>\n",
              "      <th>candidatePublisher</th>\n",
              "      <th>candidate_ds</th>\n",
              "      <th>candidateAttPrefix</th>\n",
              "      <th>candidateKey</th>\n",
              "      <th>yt1</th>\n",
              "      <th>yt2</th>\n",
              "      <th>yt3</th>\n",
              "      <th>value</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_cpdoycs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>cpdoycs</td>\n",
              "      <td>0JUSLET_cpdoycs</td>\n",
              "      <td>Payscale Minimum is property of 150930 Organog...</td>\n",
              "      <td>Payscale Minimum is property of 150930 Organog...</td>\n",
              "      <td>Payscale Minimum is property of 150930 Organog...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jfcykcm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jfcykcm</td>\n",
              "      <td>0JUSLET_jfcykcm</td>\n",
              "      <td>Parent Department is property of 150930 Organo...</td>\n",
              "      <td>Parent Department is property of 150930 Organo...</td>\n",
              "      <td>Parent Department is property of 150930 Organo...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jnmpagp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jnmpagp</td>\n",
              "      <td>0JUSLET_jnmpagp</td>\n",
              "      <td>Organisation is property of 150930 Organogram ...</td>\n",
              "      <td>Organisation is property of 150930 Organogram ...</td>\n",
              "      <td>Organisation is property of 150930 Organogram ...</td>\n",
              "      <td>ALT</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_liuxawt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>liuxawt</td>\n",
              "      <td>0JUSLET_liuxawt</td>\n",
              "      <td>Reporting Senior Post is property of 150930 Or...</td>\n",
              "      <td>Reporting Senior Post is property of 150930 Or...</td>\n",
              "      <td>Reporting Senior Post is property of 150930 Or...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_mccsbjf</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>Organisation is property of her majestys reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>mccsbjf</td>\n",
              "      <td>0JUSLET_mccsbjf</td>\n",
              "      <td>Grade is property of 150930 Organogram Data Ho...</td>\n",
              "      <td>Grade is property of 150930 Organogram Data Ho...</td>\n",
              "      <td>Grade is property of 150930 Organogram Data Ho...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  collectionName                             gtKey  ... value data_type\n",
              "0       salaries  0G81FDQ_clxhxmv--0JUSLET_cpdoycs  ...   IND     train\n",
              "1       salaries  0G81FDQ_clxhxmv--0JUSLET_jfcykcm  ...   IND     train\n",
              "2       salaries  0G81FDQ_clxhxmv--0JUSLET_jnmpagp  ...   ALT     train\n",
              "3       salaries  0G81FDQ_clxhxmv--0JUSLET_liuxawt  ...   IND     train\n",
              "4       salaries  0G81FDQ_clxhxmv--0JUSLET_mccsbjf  ...   IND     train\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "raKNGsJ7byr8",
        "outputId": "b0650138-4149-4257-aaf0-beba5e35c0ba"
      },
      "source": [
        "clean_data(raw_data, ['xt1','xt2','xt3','yt1','yt2','yt3',])\n",
        "raw_data.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>collectionName</th>\n",
              "      <th>gtKey</th>\n",
              "      <th>target_ds</th>\n",
              "      <th>targetAttPrefix</th>\n",
              "      <th>targetKey</th>\n",
              "      <th>xt1</th>\n",
              "      <th>xt2</th>\n",
              "      <th>xt3</th>\n",
              "      <th>candidate_ds</th>\n",
              "      <th>candidateAttPrefix</th>\n",
              "      <th>candidateKey</th>\n",
              "      <th>yt1</th>\n",
              "      <th>yt2</th>\n",
              "      <th>yt3</th>\n",
              "      <th>value</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_cpdoycs</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>cpdoycs</td>\n",
              "      <td>0JUSLET_cpdoycs</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jfcykcm</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jfcykcm</td>\n",
              "      <td>0JUSLET_jfcykcm</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jnmpagp</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jnmpagp</td>\n",
              "      <td>0JUSLET_jnmpagp</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>ALT</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_liuxawt</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>liuxawt</td>\n",
              "      <td>0JUSLET_liuxawt</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_mccsbjf</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>mccsbjf</td>\n",
              "      <td>0JUSLET_mccsbjf</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  collectionName                             gtKey  ... value data_type\n",
              "0       salaries  0G81FDQ_clxhxmv--0JUSLET_cpdoycs  ...   IND     train\n",
              "1       salaries  0G81FDQ_clxhxmv--0JUSLET_jfcykcm  ...   IND     train\n",
              "2       salaries  0G81FDQ_clxhxmv--0JUSLET_jnmpagp  ...   ALT     train\n",
              "3       salaries  0G81FDQ_clxhxmv--0JUSLET_liuxawt  ...   IND     train\n",
              "4       salaries  0G81FDQ_clxhxmv--0JUSLET_mccsbjf  ...   IND     train\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "OiU6aQOX4IaW",
        "outputId": "4abc950f-e113-4628-9b6b-a5aad7ed55cd"
      },
      "source": [
        "dfg = raw_data.groupby(['value'])['value'].count()\n",
        "dfg.plot(kind='bar', title='Data distribution', ylabel='Count', xlabel='Entailment Relation', figsize=(6, 5))\n",
        "raw_data.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>collectionName</th>\n",
              "      <th>gtKey</th>\n",
              "      <th>target_ds</th>\n",
              "      <th>targetAttPrefix</th>\n",
              "      <th>targetKey</th>\n",
              "      <th>xt1</th>\n",
              "      <th>xt2</th>\n",
              "      <th>xt3</th>\n",
              "      <th>candidate_ds</th>\n",
              "      <th>candidateAttPrefix</th>\n",
              "      <th>candidateKey</th>\n",
              "      <th>yt1</th>\n",
              "      <th>yt2</th>\n",
              "      <th>yt3</th>\n",
              "      <th>value</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_cpdoycs</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>cpdoycs</td>\n",
              "      <td>0JUSLET_cpdoycs</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>payscale minimum is property of 150930 organog...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jfcykcm</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jfcykcm</td>\n",
              "      <td>0JUSLET_jfcykcm</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>parent department is property of 150930 organo...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_jnmpagp</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>jnmpagp</td>\n",
              "      <td>0JUSLET_jnmpagp</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>organisation is property of 150930 organogram ...</td>\n",
              "      <td>ALT</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_liuxawt</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>liuxawt</td>\n",
              "      <td>0JUSLET_liuxawt</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>reporting senior post is property of 150930 or...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>salaries</td>\n",
              "      <td>0G81FDQ_clxhxmv--0JUSLET_mccsbjf</td>\n",
              "      <td>0G81FDQ</td>\n",
              "      <td>clxhxmv</td>\n",
              "      <td>0G81FDQ_clxhxmv</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>organisation is property of her majestys reven...</td>\n",
              "      <td>0JUSLET</td>\n",
              "      <td>mccsbjf</td>\n",
              "      <td>0JUSLET_mccsbjf</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>grade is property of 150930 organogram data ho...</td>\n",
              "      <td>IND</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  collectionName                             gtKey  ... value data_type\n",
              "0       salaries  0G81FDQ_clxhxmv--0JUSLET_cpdoycs  ...   IND     train\n",
              "1       salaries  0G81FDQ_clxhxmv--0JUSLET_jfcykcm  ...   IND     train\n",
              "2       salaries  0G81FDQ_clxhxmv--0JUSLET_jnmpagp  ...   ALT     train\n",
              "3       salaries  0G81FDQ_clxhxmv--0JUSLET_liuxawt  ...   IND     train\n",
              "4       salaries  0G81FDQ_clxhxmv--0JUSLET_mccsbjf  ...   IND     train\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "## 2.2. Parse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeyVCXT31EZQ"
      },
      "source": [
        "Clean up descriptors in dataset, remove unwanted columns from dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2IwVKFw7kFS"
      },
      "source": [
        "Spliting into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "2u3idPIJ6t7l",
        "outputId": "7ff574c9-4cff-4246-f943-a2a131b5fc84"
      },
      "source": [
        "#DATA SPLIT\n",
        "label_dict = {label: i for i, label in enumerate(raw_data.value.unique())}\n",
        "print(label_dict)\n",
        "\n",
        "#BEFORE\n",
        "#raw_data['data_type'] = ['not_set']*raw_data.shape[0]\n",
        "#raw_data.loc[X_train, 'data_type'] = 'train'\n",
        "#raw_data.loc[X_val, 'data_type'] = 'val'\n",
        "\n",
        "#AFTER\n",
        "#raw_data['data_type'] = ['not_set']*raw_data.shape[0]\n",
        "\n",
        "raw_data['label'] = raw_data.value.replace(label_dict)\n",
        "raw_data.groupby(['value', 'data_type']).count()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'IND': 0, 'ALT': 1, 'EQ': 2, 'REV': 3, 'FWD': 4}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>collectionName</th>\n",
              "      <th>gtKey</th>\n",
              "      <th>target_ds</th>\n",
              "      <th>targetAttPrefix</th>\n",
              "      <th>targetKey</th>\n",
              "      <th>xt1</th>\n",
              "      <th>xt2</th>\n",
              "      <th>xt3</th>\n",
              "      <th>candidate_ds</th>\n",
              "      <th>candidateAttPrefix</th>\n",
              "      <th>candidateKey</th>\n",
              "      <th>yt1</th>\n",
              "      <th>yt2</th>\n",
              "      <th>yt3</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">ALT</th>\n",
              "      <th>train</th>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "      <td>4335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">EQ</th>\n",
              "      <th>train</th>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "      <td>2623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">FWD</th>\n",
              "      <th>train</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">IND</th>\n",
              "      <th>train</th>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "      <td>583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "      <td>5300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">REV</th>\n",
              "      <th>train</th>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 collectionName  gtKey  target_ds  ...   yt2   yt3  label\n",
              "value data_type                                    ...                   \n",
              "ALT   train                4335   4335       4335  ...  4335  4335   4335\n",
              "      val                    44     44         44  ...    44    44     44\n",
              "EQ    train                2623   2623       2623  ...  2623  2623   2623\n",
              "      val                    35     35         35  ...    35    35     35\n",
              "FWD   train                   8      8          8  ...     8     8      8\n",
              "      val                    26     26         26  ...    26    26     26\n",
              "IND   train                 583    583        583  ...   583   583    583\n",
              "      val                  5300   5300       5300  ...  5300  5300   5300\n",
              "REV   train                  70     70         70  ...    70    70     70\n",
              "      val                    17     17         17  ...    17    17     17\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Let's extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldgNb_WS87dD",
        "outputId": "f039b204-aff7-4666-efd2-4b69add95551"
      },
      "source": [
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSeuas069aEa",
        "outputId": "83db0701-7800-4aad-f1a8-112dd04af814"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "txsentences = raw_data.xt3.values\n",
        "tysentences = raw_data.yt3.values\n",
        "#labels = df.label.values\n",
        "print(' Original: ', txsentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(txsentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(txsentences[0])))\n",
        "\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  organisation is property of her majestys revenue and customs 30 09 2011 hmrc 300911 hmrc organogram final junior and is related to parent department and unit and has values her majesty's revenue and customs\n",
            "Tokenized:  ['organisation', 'is', 'property', 'of', 'her', 'majesty', '##s', 'revenue', 'and', 'customs', '30', '09', '2011', 'hm', '##rc', '300', '##9', '##11', 'hm', '##rc', 'organ', '##og', '##ram', 'final', 'junior', 'and', 'is', 'related', 'to', 'parent', 'department', 'and', 'unit', 'and', 'has', 'values', 'her', 'majesty', \"'\", 's', 'revenue', 'and', 'customs']\n",
            "Token IDs:  [5502, 2003, 3200, 1997, 2014, 9995, 2015, 6599, 1998, 8205, 2382, 5641, 2249, 20287, 11890, 3998, 2683, 14526, 20287, 11890, 5812, 8649, 6444, 2345, 3502, 1998, 2003, 3141, 2000, 6687, 2533, 1998, 3131, 1998, 2038, 5300, 2014, 9995, 1005, 1055, 6599, 1998, 8205]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOk_a-Cx-mlp",
        "outputId": "c4f2b6ab-3307-4d40-f271-816b3c12b15f"
      },
      "source": [
        "max_l = 0\n",
        "\n",
        "for sent in txsentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True) # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    max_l = max(max_l, len(input_ids))    # Update the maximum sentence length.\n",
        "\n",
        "for sent in tysentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_l = max(max_l, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_l)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld4pu9dg99A3"
      },
      "source": [
        "Tokenizing all dataset will:\n",
        "  (1) Tokenize the sentence.<br>\n",
        "  (2) Prepend the `[CLS]` token to the start.<br>\n",
        "  (3) Append the `[SEP]` token to the end.<br>\n",
        "  (4) Map tokens to their IDs.<br>\n",
        "  (5) Pad or truncate the sentence to `max_length`<br>\n",
        "  (6) Create attention masks for [PAD] tokens.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z3ft3IM-AzN"
      },
      "source": [
        "max_len = 256\n",
        "#max_len = 128\n",
        "encoded_data_train = tokenizer.batch_encode_plus(zip(raw_data[raw_data.data_type=='train'].xt3.values.tolist(), raw_data[raw_data.data_type=='train'].yt3.values.tolist()), \n",
        "                                                 is_split_into_words=False, \n",
        "                                                 padding=True,\n",
        "                                                 add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "                                                 return_attention_mask=True,# Construct attn. masks.\n",
        "                                                 max_length=max_len,# Pad & truncate all sentences.\n",
        "                                                 return_tensors='pt')# Return pytorch tensors.\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(raw_data[raw_data.data_type=='train'].label.values)\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(zip(raw_data[raw_data.data_type=='val'].xt3.values.tolist(), raw_data[raw_data.data_type=='val'].yt3.values.tolist()),\n",
        "                                               is_split_into_words=False, \n",
        "                                               padding=True,\n",
        "                                               add_special_tokens=True,\n",
        "                                               return_attention_mask=True,\n",
        "                                               max_length=max_len,\n",
        "                                               return_tensors='pt')\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(raw_data[raw_data.data_type=='val'].label.values)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEUSEhoqDmUo"
      },
      "source": [
        "Visual Characterization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOp4opzNCYe4",
        "outputId": "be9b8d6d-72ae-45d8-de32-0c57b50d7ed6"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
        "len(dataset_train), len(dataset_val)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7619, 5422)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_p9KetCC3G1"
      },
      "source": [
        "Create dataset iterator by using torch DataLoader class. This avoids loading the dataset into memory, which is memory efficient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLYAzLf8C6Af"
      },
      "source": [
        "BATCH_SIZE = 3 #DataLoader needs to know this (BERT recomendation is 16 or 32)\n",
        "#BATCH_SIZE = 16 #DataLoader needs to know this (BERT recomendation is 16 or 32)\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, #training samples\n",
        "                              sampler=RandomSampler(dataset_train), #select batches randomly\n",
        "                              batch_size=BATCH_SIZE)#train with this batch size\n",
        "dataloader_validation = DataLoader(dataset_val, #validation samples\n",
        "                                   sampler=SequentialSampler(dataset_val), #take batches sequentially\n",
        "                                   batch_size=BATCH_SIZE)# evaluate using this batch size"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "# 4. Set up Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX"
      },
      "source": [
        "Configuring model..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_YUH6r7ENjW",
        "outputId": "06f67374-4d5d-4ed1-93d0-669fd3a0bebf"
      },
      "source": [
        "EPOCHS = 5\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",  #Use 12-layer BERT model, with uncased vocab.\n",
        "                                                      num_labels=len(label_dict), #number of output labels\n",
        "                                                      output_attentions=False, #Whether model returns attentions weights\n",
        "                                                      output_hidden_states=False)#Whether the model returns all hidden-states\n",
        "\n",
        "#Weight Decay fix\n",
        "optimizer = AdamW(model.parameters(), \n",
        "                  lr=1e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps=1e-8)# args.adam_epsilon  - default is 1e-8.\n",
        "\n",
        "#learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*EPOCHS)\n",
        "\n",
        "model.cuda()                                                      "
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc4Qxfw1Frbc",
        "outputId": "f3cafd11-9703-4053-a776-ee3572fbc6f4"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## 4.1. Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUAH8qQSMnn1"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "  label_dict_inverse = {v: k for k, v in label_dict.items()}  \n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "\n",
        "  for label in np.unique(labels_flat):\n",
        "    y_preds = preds_flat[labels_flat==label]\n",
        "    y_true = labels_flat[labels_flat==label]\n",
        "    print(f'Class: {label_dict_inverse[label]}')\n",
        "    print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}' + ', ' + str(len(y_preds[y_preds==label])/len(y_true)) + '\\n')\n",
        "\n",
        "def evaluate(model, dataloader_val, device):\n",
        "  model.eval()\n",
        "  loss_val_total = 0\n",
        "  predictions, true_vals = [], []\n",
        "    \n",
        "  for batch in dataloader_val:   \n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "    inputs = {'input_ids':      batch[0],\n",
        "              'attention_mask': batch[1],\n",
        "              'labels':         batch[2],\n",
        "              }\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**inputs)\n",
        "      \n",
        "      loss = outputs[0]\n",
        "      logits = outputs[1]\n",
        "      loss_val_total += loss.item()\n",
        "\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = inputs['labels'].cpu().numpy()\n",
        "      predictions.append(logits)\n",
        "      true_vals.append(label_ids)\n",
        "    \n",
        "  loss_val_avg = loss_val_total/len(dataloader_val)   \n",
        "  predictions = np.concatenate(predictions, axis=0)\n",
        "  true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "  return loss_val_avg, predictions, true_vals\n",
        "\n",
        "def single_eval():\n",
        "  print(\"single eval\")\n",
        "\n",
        "def train(model, epochs,dataloader_train, dataloader_validation, optimizer, scheduler, device='cpu'):\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  for epoch in tqdm(range(1, epochs+1)):\n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "      model.zero_grad()\n",
        "      batch = tuple(b.to(device) for b in batch)\n",
        "      inputs = {'input_ids': batch[0],\n",
        "                'attention_mask': batch[1],\n",
        "                'labels': batch[2],\n",
        "                }       \n",
        "      outputs = model(**inputs)\n",
        "        \n",
        "      loss = outputs[0]\n",
        "      loss_train_total += loss.item()\n",
        "      loss.backward()\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "        \n",
        "      progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "    #torch.save(model.state_dict(), f'./models/finetuned_BERT_epoch_{epoch}.model')   \n",
        "    torch.save(model.state_dict(), f'gdrive/MyDrive/models/finetuned_BERT_epoch_{epoch}.model')   \n",
        "\n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(model, dataloader_validation, device=device)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz5Qlp6hsMDj"
      },
      "source": [
        "## 4.2. Verbose Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1hffmqsQzk"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def train_verbose_model(model, epochs,dataloader_train, dataloader_validation, optimizer, scheduler, device='cpu'):\n",
        "  # We'll store a number of quantities such as training and validation loss, \n",
        "  # validation accuracy, and timings.\n",
        "  training_stats = []\n",
        "\n",
        "  # Measure the total training time for the whole run.\n",
        "  total_t0 = time.time()\n",
        "\n",
        "  # For each epoch...\n",
        "  for epoch_i in range(0, epochs):\n",
        "      # ========================================\n",
        "      #               Training\n",
        "      # ========================================\n",
        "      \n",
        "      # Perform one full pass over the training set.\n",
        "      print(\"\")\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "      print('Training...')\n",
        "\n",
        "      # Measure how long the training epoch takes.\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Reset the total loss for this epoch.\n",
        "      total_train_loss = 0\n",
        "\n",
        "      # Put the model into training mode. Don't be mislead--the call to \n",
        "      # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "      # `dropout` and `batchnorm` layers behave differently during training\n",
        "      # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "      model.train()\n",
        "\n",
        "      # For each batch of training data...\n",
        "      for step, batch in enumerate(dataloader_train):\n",
        "\n",
        "          # Progress update every 40 batches.\n",
        "          #if step % 40 == 0 and not step == 0:\n",
        "          if step % 200 == 0 and not step == 0:\n",
        "              # Calculate elapsed time in minutes.\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "              # Report progress.\n",
        "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(dataloader_train), elapsed))\n",
        "\n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "          # `to` method.\n",
        "          #\n",
        "          # `batch` contains three pytorch tensors:\n",
        "          #   [0]: input ids \n",
        "          #   [1]: attention masks\n",
        "          #   [2]: labels \n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "\n",
        "          # Always clear any previously calculated gradients before performing a\n",
        "          # backward pass. PyTorch doesn't do this automatically because \n",
        "          # accumulating the gradients is \"convenient while training RNNs\". \n",
        "          # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "          model.zero_grad()        \n",
        "\n",
        "          # Perform a forward pass (evaluate the model on this training batch).\n",
        "          # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "          # function and pass down the arguments. The `forward` function is \n",
        "          # documented here: \n",
        "          # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "          # The results are returned in a results object, documented here:\n",
        "          # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "          # Specifically, we'll get the loss (because we provided labels) and the\n",
        "          # \"logits\"--the model outputs prior to activation.\n",
        "          result = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels,\n",
        "                        return_dict=True)\n",
        "\n",
        "          loss = result.loss\n",
        "          logits = result.logits\n",
        "\n",
        "          # Accumulate the training loss over all of the batches so that we can\n",
        "          # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "          # single value; the `.item()` function just returns the Python value \n",
        "          # from the tensor.\n",
        "          total_train_loss += loss.item()\n",
        "\n",
        "          # Perform a backward pass to calculate the gradients.\n",
        "          loss.backward()\n",
        "\n",
        "          # Clip the norm of the gradients to 1.0.\n",
        "          # This is to help prevent the \"exploding gradients\" problem.\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "          # Update parameters and take a step using the computed gradient.\n",
        "          # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "          # modified based on their gradients, the learning rate, etc.\n",
        "          optimizer.step()\n",
        "\n",
        "          # Update the learning rate.\n",
        "          scheduler.step()\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_train_loss = total_train_loss / len(dataloader_train)            \n",
        "      \n",
        "      # Measure how long this epoch took.\n",
        "      training_time = format_time(time.time() - t0)\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "      print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "          \n",
        "      # ========================================\n",
        "      #               Validation\n",
        "      # ========================================\n",
        "      # After the completion of each training epoch, measure our performance on\n",
        "      # our validation set.\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Running Validation...\")\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Put the model in evaluation mode--the dropout layers behave differently\n",
        "      # during evaluation.\n",
        "      model.eval()\n",
        "\n",
        "      # Tracking variables \n",
        "      total_eval_accuracy = 0\n",
        "      total_eval_loss = 0\n",
        "      nb_eval_steps = 0\n",
        "\n",
        "      # Evaluate data for one epoch\n",
        "      for batch in dataloader_validation:\n",
        "          \n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "          # the `to` method.\n",
        "          #\n",
        "          # `batch` contains three pytorch tensors:\n",
        "          #   [0]: input ids \n",
        "          #   [1]: attention masks\n",
        "          #   [2]: labels \n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "          \n",
        "          # Tell pytorch not to bother with constructing the compute graph during\n",
        "          # the forward pass, since this is only needed for backprop (training).\n",
        "          with torch.no_grad():        \n",
        "\n",
        "              # Forward pass, calculate logit predictions.\n",
        "              # token_type_ids is the same as the \"segment ids\", which \n",
        "              # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "              result = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_labels,\n",
        "                            return_dict=True)\n",
        "\n",
        "          # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "          # output values prior to applying an activation function like the \n",
        "          # softmax.\n",
        "          loss = result.loss\n",
        "          logits = result.logits\n",
        "              \n",
        "          # Accumulate the validation loss.\n",
        "          total_eval_loss += loss.item()\n",
        "\n",
        "          # Move logits and labels to CPU\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "          # Calculate the accuracy for this batch of test sentences, and\n",
        "          # accumulate it over all batches.\n",
        "          total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "          \n",
        "\n",
        "      # Report the final accuracy for this validation run.\n",
        "      avg_val_accuracy = total_eval_accuracy / len(dataloader_validation)\n",
        "      print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_val_loss = total_eval_loss / len(dataloader_validation)\n",
        "      \n",
        "      # Measure how long the validation run took.\n",
        "      validation_time = format_time(time.time() - t0)\n",
        "      \n",
        "      print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "      print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "      # Record all statistics from this epoch.\n",
        "      training_stats.append(\n",
        "          {\n",
        "              'epoch': epoch_i + 1,\n",
        "              'Training Loss': avg_train_loss,\n",
        "              'Valid. Loss': avg_val_loss,\n",
        "              'Valid. Accur.': avg_val_accuracy,\n",
        "              'Training Time': training_time,\n",
        "              'Validation Time': validation_time\n",
        "          }\n",
        "      )\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "\n",
        "  print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "  return training_stats"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.3. Execute Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhUEl5RPMheo",
        "outputId": "fccc3b2c-8928-4d6e-ae5d-94e6c593eb90"
      },
      "source": [
        "seed_val = 17#42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)    \n",
        "\n",
        "#train(model, EPOCHS, dataloader_train, dataloader_validation, optimizer, scheduler, device=DEVICE)\n",
        "my_stats = train_verbose_model(model, EPOCHS, dataloader_train, dataloader_validation, optimizer, scheduler, device=DEVICE)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch   200  of  2,540.    Elapsed: 0:01:57.\n",
            "  Batch   400  of  2,540.    Elapsed: 0:03:52.\n",
            "  Batch   600  of  2,540.    Elapsed: 0:05:48.\n",
            "  Batch   800  of  2,540.    Elapsed: 0:07:43.\n",
            "  Batch 1,000  of  2,540.    Elapsed: 0:09:39.\n",
            "  Batch 1,200  of  2,540.    Elapsed: 0:11:34.\n",
            "  Batch 1,400  of  2,540.    Elapsed: 0:13:29.\n",
            "  Batch 1,600  of  2,540.    Elapsed: 0:15:25.\n",
            "  Batch 1,800  of  2,540.    Elapsed: 0:17:20.\n",
            "  Batch 2,000  of  2,540.    Elapsed: 0:19:15.\n",
            "  Batch 2,200  of  2,540.    Elapsed: 0:21:10.\n",
            "  Batch 2,400  of  2,540.    Elapsed: 0:23:06.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:24:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.29\n",
            "  Validation took: 0:02:24\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch   200  of  2,540.    Elapsed: 0:01:55.\n",
            "  Batch   400  of  2,540.    Elapsed: 0:03:51.\n",
            "  Batch   600  of  2,540.    Elapsed: 0:05:46.\n",
            "  Batch   800  of  2,540.    Elapsed: 0:07:41.\n",
            "  Batch 1,000  of  2,540.    Elapsed: 0:09:36.\n",
            "  Batch 1,200  of  2,540.    Elapsed: 0:11:32.\n",
            "  Batch 1,400  of  2,540.    Elapsed: 0:13:27.\n",
            "  Batch 1,600  of  2,540.    Elapsed: 0:15:22.\n",
            "  Batch 1,800  of  2,540.    Elapsed: 0:17:17.\n",
            "  Batch 2,000  of  2,540.    Elapsed: 0:19:12.\n",
            "  Batch 2,200  of  2,540.    Elapsed: 0:21:08.\n",
            "  Batch 2,400  of  2,540.    Elapsed: 0:23:03.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:24:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.22\n",
            "  Validation took: 0:02:24\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch   200  of  2,540.    Elapsed: 0:01:55.\n",
            "  Batch   400  of  2,540.    Elapsed: 0:03:50.\n",
            "  Batch   600  of  2,540.    Elapsed: 0:05:46.\n",
            "  Batch   800  of  2,540.    Elapsed: 0:07:41.\n",
            "  Batch 1,000  of  2,540.    Elapsed: 0:09:36.\n",
            "  Batch 1,200  of  2,540.    Elapsed: 0:11:31.\n",
            "  Batch 1,400  of  2,540.    Elapsed: 0:13:26.\n",
            "  Batch 1,600  of  2,540.    Elapsed: 0:15:22.\n",
            "  Batch 1,800  of  2,540.    Elapsed: 0:17:17.\n",
            "  Batch 2,000  of  2,540.    Elapsed: 0:19:12.\n",
            "  Batch 2,200  of  2,540.    Elapsed: 0:21:07.\n",
            "  Batch 2,400  of  2,540.    Elapsed: 0:23:02.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:24:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.21\n",
            "  Validation took: 0:02:24\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch   200  of  2,540.    Elapsed: 0:01:55.\n",
            "  Batch   400  of  2,540.    Elapsed: 0:03:50.\n",
            "  Batch   600  of  2,540.    Elapsed: 0:05:46.\n",
            "  Batch   800  of  2,540.    Elapsed: 0:07:41.\n",
            "  Batch 1,000  of  2,540.    Elapsed: 0:09:36.\n",
            "  Batch 1,200  of  2,540.    Elapsed: 0:11:31.\n",
            "  Batch 1,400  of  2,540.    Elapsed: 0:13:26.\n",
            "  Batch 1,600  of  2,540.    Elapsed: 0:15:21.\n",
            "  Batch 1,800  of  2,540.    Elapsed: 0:17:16.\n",
            "  Batch 2,000  of  2,540.    Elapsed: 0:19:12.\n",
            "  Batch 2,200  of  2,540.    Elapsed: 0:21:07.\n",
            "  Batch 2,400  of  2,540.    Elapsed: 0:23:02.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:24:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.26\n",
            "  Validation took: 0:02:24\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch   200  of  2,540.    Elapsed: 0:01:55.\n",
            "  Batch   400  of  2,540.    Elapsed: 0:03:50.\n",
            "  Batch   600  of  2,540.    Elapsed: 0:05:46.\n",
            "  Batch   800  of  2,540.    Elapsed: 0:07:41.\n",
            "  Batch 1,000  of  2,540.    Elapsed: 0:09:36.\n",
            "  Batch 1,200  of  2,540.    Elapsed: 0:11:31.\n",
            "  Batch 1,400  of  2,540.    Elapsed: 0:13:26.\n",
            "  Batch 1,600  of  2,540.    Elapsed: 0:15:22.\n",
            "  Batch 1,800  of  2,540.    Elapsed: 0:17:17.\n",
            "  Batch 2,000  of  2,540.    Elapsed: 0:19:12.\n",
            "  Batch 2,200  of  2,540.    Elapsed: 0:21:07.\n",
            "  Batch 2,400  of  2,540.    Elapsed: 0:23:02.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:24:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.32\n",
            "  Validation took: 0:02:24\n",
            "\n",
            "Training complete!\n",
            "Total training took 2:14:00 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "## 5. Summary of results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c9829301-5daf-46d7-8fed-043c589f27c4"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=my_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.33e-01</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0:24:26</td>\n",
              "      <td>0:02:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.78e-02</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0:24:23</td>\n",
              "      <td>0:02:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.31e-02</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0:24:23</td>\n",
              "      <td>0:02:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.29e-03</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0:24:23</td>\n",
              "      <td>0:02:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.94e-03</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0:24:23</td>\n",
              "      <td>0:02:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1           1.33e-01         0.29           0.95       0:24:26         0:02:24\n",
              "2           2.78e-02         0.22           0.95       0:24:23         0:02:24\n",
              "3           1.31e-02         0.21           0.97       0:24:23         0:02:24\n",
              "4           6.29e-03         0.26           0.96       0:24:23         0:02:24\n",
              "5           1.94e-03         0.32           0.96       0:24:23         0:02:24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "(For reference, we are using 7,695 training samples and 856 validation samples).\n",
        "\n",
        "Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on. \n",
        "\n",
        "If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "e5abb7dd-37ec-47a6-dd69-5babfd432c6b"
      },
      "source": [
        "% matplotlib inline\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KIUhsga1P_s"
      },
      "source": [
        "##5.1 Summary of metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efi7UXyX1Yci",
        "outputId": "439a944c-2e39-422c-ba4c-395b9105390b"
      },
      "source": [
        "model = model.to(DEVICE)\n",
        "# _, predictions, true_vals = evaluate(model, dataloader_test, device=DEVICE)\n",
        "_, predictions, true_vals = evaluate(model, dataloader_validation, device=DEVICE)\n",
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: IND\n",
            "Accuracy: 5152/5300, 0.9720754716981133\n",
            "\n",
            "Class: ALT\n",
            "Accuracy: 24/44, 0.5454545454545454\n",
            "\n",
            "Class: EQ\n",
            "Accuracy: 3/35, 0.08571428571428572\n",
            "\n",
            "Class: REV\n",
            "Accuracy: 0/17, 0.0\n",
            "\n",
            "Class: FWD\n",
            "Accuracy: 0/26, 0.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "RkS3ENpI1n1m",
        "outputId": "8f5b1a45-139e-4de9-dd41-42369dadf928"
      },
      "source": [
        "y_pred = np.argmax(predictions, axis=1)\n",
        "print(classification_report(true_vals, y_pred, target_names=list(label_dict.keys())))\n",
        "#print(classification_report(true_vals, y_pred, target_names=[\"IND\",\"EQ\",\"ALT\"]))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6340515a3426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(classification_report(true_vals, y_pred, target_names=[\"IND\",\"EQ\",\"ALT\"]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FdZ67aW1yMn",
        "outputId": "4f7cc69c-d5c9-4179-90e9-70cdd7bd34d7"
      },
      "source": [
        "len(dataset_train), len(dataset_val)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7619, 5422)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7619, 5422)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    }
  ]
}